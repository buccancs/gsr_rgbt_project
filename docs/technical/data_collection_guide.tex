\documentclass{article}
\usepackage{amsmath,graphicx, algorithm, algorithmic, subscript}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\begin{document}

\title{GSR-RGBT Project Data Collection Guide}
\author{GSR-RGBT Project Team}
\date{\today}
\maketitle

\tableofcontents

\section{Overview}

This comprehensive guide consolidates all aspects of data collection for the GSR-RGBT project, including experimental procedures, equipment setup, task design, and data management. It combines practical implementation details with theoretical justification for the experimental design.

\section{Task Selection and Purpose}

The experimental tasks were chosen to elicit distinct physiological and emotional states, aligning to model GSR from facial cues:

\begin{itemize}
    \item \textbf{Baseline (Rest)} -- A 5-minute neutral rest period provides a personalised physiological baseline for each participant. By recording GSR and facial video with minimal stimuli, we can normalise subsequent responses and distinguish task effects from individual differences.
    \item \textbf{Math Stressor (Cognitive Stress)} -- The mental arithmetic task is a well-known stress induction method. It reliably increases sympathetic arousal, raising GSR, while the subject's face may show signs of concentration (e.g., subtle facial muscle tension). This task is included to capture how cognitive stress correlates with both RGB and thermal facial signals.
    \item \textbf{Relaxation (Recovery)} -- Interleaving a relaxation period (guided breathing or calm video) allows the participant's physiology to return toward baseline after stress. Modelling requires examples of both rising and falling GSR. The relaxation task helps the model learn recovery dynamics and tests whether observed changes are due to the stressor, not sensor drift.
    \item \textbf{Emotional Video (Affective Response)} -- An emotionally charged video clip (positive or negative content) evokes affective arousal distinct from cognitive stress. Facial expressions and thermal patterns can reflect emotion-driven perspiration changes. This task ensures the model covers a range of GSR-inducing conditions (stress vs. emotion) and helps generalise the predictor to real-world scenarios.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{../references/task_timeline.png}
    \caption{Timeline of experimental tasks showing the 20-minute protocol: 5-minute baseline rest period, 3-minute math stressor task, 1-minute inter-task rest, 5-minute guided relaxation, 1-minute inter-task rest, 3-minute emotional video stimulus, and 2-minute final rest period. The timeline includes expected GSR response patterns for each phase.}
\end{figure}

\section{Experimental Task Order}

The session consists of the following tasks in sequence:

\begin{itemize}
    \item \textbf{Baseline (Rest):} 5 minutes of quiet rest. The participant sits quietly, fixating on a neutral cross or blank screen to establish a physiological baseline.
    \item \textbf{Math Stressor (Cognitive Task):} 3 minutes of mentally solving difficult arithmetic problems presented on a screen. Time pressure and immediate feedback are provided to induce cognitive stress.
    \item \textbf{Inter-Task Rest:} 1 minute of quiet rest following the math task to allow partial recovery.
    \item \textbf{Relaxation (Recovery):} 5 minutes of guided deep breathing or viewing a calming nature video to induce physiological relaxation and allow GSR to return towards baseline.
    \item \textbf{Inter-Task Rest:} 1 minute of rest after the relaxation period.
    \item \textbf{Emotional Video (Affective Stimulus):} 3-minute emotionally arousing video clip (e.g., suspenseful or joyful scenes) to elicit an emotional response.
    \item \textbf{Final Rest:} 2 minutes of rest after the video to capture the recovery phase.
\end{itemize}

\begin{table}[h]
    \centering
    \caption{Task durations and inter-task intervals}
    \begin{tabular}{ll}
        \hline
        Task/Interval   & Duration  \\
        \hline
        Baseline rest   & 5 minutes \\
        Math stressor   & 3 minutes \\
        Inter-task rest & 1 minute  \\
        Relaxation      & 5 minutes \\
        Inter-task rest & 1 minute  \\
        Emotional video & 3 minutes \\
        Final rest      & 2 minutes \\
        \hline
    \end{tabular}
\end{table}

\section{Participant Handling}

\begin{itemize}
    \item \textbf{Recruitment and Consent:} Recruit adult participants with normal or corrected vision and no skin conditions. Explain the study purpose, obtain informed consent, and collect demographic information (age, gender, skin tone).
    \item \textbf{Preparation:} Allow participants to acclimate to the room for 5 minutes before starting. Clean the skin on the hands where GSR electrodes will be applied.
    \item \textbf{Electrode Attachment:} Attach the Shimmer GSR sensor electrodes to two adjacent fingertips (e.g., index and middle finger of the left hand) using conductive gel. Attach the PhysioKit GSR sensor to two fingertips of the right hand. Ensure secure contact and verify signal quality.
    \item \textbf{Seating and Comfort:} Seat the participant in front of the cameras at a fixed distance (approximately 1.0–1.5 meters). Adjust chair and camera height so the participant's face is centred. Instruct the participant to remain as still as possible.
    \item \textbf{Instructions:} Verbally explain the task sequence and allow a brief practice if necessary. Remind participants to avoid speaking or unnecessary movements during tasks.
\end{itemize}

\section{Equipment and Setup Justification}

The setup design is optimised for capturing relevant signals reliably:

\begin{itemize}
    \item \textbf{Camera Angles:} Both RGB and thermal cameras are positioned directly in front of the participant to maximise unobstructed facial views. A slight downward tilt may be used to centre the face. This frontal angle captures facial blood perfusion (for rPPG) and forehead/nasal-periorbital regions (for thermal) without distortion.
    \item \textbf{Lighting:} For the RGB camera, uniform diffuse lighting (e.g., LED panels) is used to minimise shadows and specular highlights, which can interfere with colour-based analysis. The lighting level is kept constant across sessions. The thermal camera requires no visible light; however, ambient temperature is controlled (e.g., 22°C) to ensure consistent heat measurements.
    \item \textbf{Sensor Placement:} Shimmer and PhysioKit GSR sensors are placed on palmar finger surfaces because these areas have high sweat gland density. We attach them to different hands to avoid interfering with each other and to distribute workload (dominant vs. non-dominant hand). This redundancy guards against single-sensor failure and allows cross-validation of GSR signals.
    \item \textbf{Environment Controls:} The recording room is quiet, with stable climate (temperature and humidity) to prevent environmental fluctuations from affecting sensors. We remove background stimuli (plain walls, no posters) so that the only video input is the planned stimuli. Participants are asked to remove glasses, hats, or heavy makeup that could reflect light or insulate heat.
\end{itemize}

\section{Camera and Sensor Setup}

\begin{itemize}
    \item \textbf{RGB Camera:} One high-definition RGB camera (e.g., 1920x1080 at 30 fps) mounted on a tripod in front of the participant at eye level, approximately 1–1.5 meters away. The camera frame is centered on the participant's face. Diffuse, uniform visible lighting is used to ensure clear facial illumination without glare.
    \item \textbf{Thermal Camera:} One thermal infrared camera (e.g., 640x480 at 30 fps) co-located with the RGB camera so that both cameras have a similar field of view. The camera is calibrated for human skin emissivity, and ambient temperature is controlled to avoid thermal drift.
    \item \textbf{Shimmer GSR Sensor:} Attach the Shimmer3 GSR+ sensor to two fingers (e.g., index and middle fingers) of the left hand. Sample the GSR signal at a high rate (e.g., 32–128 Hz) and stream or log data to a PC.
    \item \textbf{PhysioKit GSR Sensor:} Attach an additional GSR sensor from PhysioKit to two fingertips of the right hand. Configure the sampling rate similarly to Shimmer (e.g., 32–128 Hz). This provides a redundant GSR measurement for reliability checking.
    \item \textbf{Other Sensors (Optional):} (If applicable) Place any additional sensors (e.g., pulse oximeter, EMG) according to their guidelines, ensuring wires do not obstruct the face or interfere with the cameras.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{../references/experimental_setup.png}
    \caption{Schematic of the experimental setup showing the participant seated in front of the RGB and thermal cameras (mounted on tripods), with GSR sensors attached to both hands. The left hand has the Shimmer GSR+ sensor, while the right hand has the PhysioKit GSR sensor. The cameras are positioned to capture the participant's face with uniform lighting.}
\end{figure}

\section{Fairness and Diversity Considerations}

Ensuring equitable data collection across skin tones is a priority:

\begin{itemize}
    \item \textbf{Diverse Recruitment:} We plan to recruit participants representing a range of Fitzpatrick skin types. This diversity allows the model to learn from varied appearances and permits evaluation of any performance disparity after training.
    \item \textbf{Thermal Imaging Benefits:} Thermal infrared measurements capture heat emissions directly and are largely independent of visible skin pigmentation. By including thermal data, we aim to mitigate biases inherent in visible-light features (where darker skin can reduce signal quality).
    \item \textbf{Normalisation Procedures:} During data preprocessing, we will inspect and equalise signal characteristics (e.g., image brightness, facial temperature baseline) across groups. If systematic differences emerge, group-specific normalisation or augmentation will be employed.
    \item \textbf{Documentation:} We log each participant's self-reported race/ethnicity and skin tone category. This metadata is used post hoc to check that model errors do not disproportionately affect any group.
\end{itemize}

\section{Synchronisation Strategy and Reliability}

Robust synchronisation is crucial for matching GSR samples to video frames:

\begin{itemize}
    \item \textbf{Primary Sync (Software):} Where possible, devices share a common clock (e.g., all connected to the same computer) so that GSR streams and video frames have consistent timestamps. PhysioKit's software and Shimmer's API both support timestamped data logging.
    \item \textbf{Redundant Markers:} We use an LED flash at the session start, which produces a spike in video luminance (and slight thermal change) simultaneously visible in RGB and IR. An audible clap or beep is also recorded by the camera's microphone and may induce a tiny GSR response, providing a cross-check.
    \item \textbf{Fallback Mechanisms:} If wireless connections fail, Shimmer stores data on onboard SD cards for later retrieval. We then align data offline using the recorded event markers. Experimenters keep a synced stopwatch and note the real times of task events as an extra reference.
    \item \textbf{Verification and Correction:} After data collection, we verify alignment by overlaying GSR peaks with video cues. Minor desynchronizations are corrected by shifting one time series. This ensures that every GSR waveform point is correctly paired with the corresponding video frame.
\end{itemize}

\subsection{Detailed Synchronization Methods}

Accurate synchronisation of video and GSR data streams is achieved by multiple methods:

\begin{itemize}
    \item \textbf{Timestamp Alignment:} Use the acquisition computer's clock to timestamp both video frames and GSR samples. Whenever possible, connect devices to the same host or synchronise their clocks (e.g., via NTP).
    \item \textbf{Visual Marker:} At the start of recording, a bright LED flash is triggered and captured by both RGB and thermal cameras. This creates a sharp, simultaneous frame marker in the video data.
    \item \textbf{Audio/Physical Cue:} The participant or experimenter produces a hand clap or button click at the start and end of certain tasks. The clap sound (if the camera has a microphone) and any small motion artifact in the GSR create additional sync points across modalities.
    \item \textbf{Event Logging:} Use the experiment control software (or PhysioKit interface) to insert event markers (e.g., "Task Start", "Task End") into the data log. Manually note any irregular events or delays.
    \item \textbf{Post-Hoc Verification:} After recording, visually inspect the videos and GSR traces to confirm alignment (e.g., matching LED frame to recorded spike). Apply any constant offset correction if needed.
\end{itemize}

\section{Data Pipeline and Model Integration}

Collected data directly feeds into the predictive modelling pipeline:

\begin{itemize}
    \item \textbf{Feature Extraction:} We will preprocess the RGB video to extract facial regions and compute rPPG signals (colour channel fluctuations) and expression features. Thermal frames will yield facial heat maps and temperature-derived features. These features form the input space for the model.
    \item \textbf{Target Signal:} The continuous GSR waveforms from Shimmer (and PhysioKit) serve as ground truth targets. Synchronised GSR values (sampled at e.g. 32 Hz) are matched to corresponding video frame timestamps.
    \item \textbf{Model Training:} Using supervised learning, models (e.g., regression or neural networks) will be trained to map video-derived features to GSR values. We will include task labels as contextual input to help the model distinguish stress vs. relaxation contexts.
    \item \textbf{Fairness Validation:} The trained model's performance will be evaluated separately on subsets of data (e.g., different skin tone groups). We will compute metrics such as RMSE and correlation for each group to ensure no significant disparity. If biases appear, we will consider re-weighting or data augmentation strategies.
    \item \textbf{Scientific Alignment:} This protocol ensures the dataset has the necessary variation (cognitive stress vs. emotional arousal) to train a generalizable GSR predictor. By carefully documenting tasks and conditions, the modelling can directly test how visual cues relate to autonomic arousal.
\end{itemize}

\section{Data Labelling and Format}

\begin{itemize}
    \item \textbf{Task Labels:} Each data file or segment is labelled with the corresponding task (e.g., \texttt{BASELINE}, \texttt{MATH}, \texttt{RELAX}, \texttt{VIDEO}). Annotate start and end times of tasks in a metadata file.
    \item \textbf{Data Files:} Save RGB and thermal video files in a lossless or high-quality format (e.g., MP4 with high bitrate, or image frame sequences). Save GSR data streams from each device as CSV or binary files with timestamps.
    \item \textbf{Metadata Logging:} Maintain a master metadata log (e.g., \texttt{session\_info.csv}) including Subject ID, session date/time, device IDs, sampling rates, and any calibration values. Record the event markers and any noted issues.
    \item \textbf{Quality Checks:} After each session, verify that data are recorded without dropouts. If any segment is missing or noisy, note this in the metadata and plan for re-recording if necessary.
\end{itemize}

\section{File Structure and Naming Convention}

\begin{itemize}
    \item \textbf{Directory Layout:} Organize data by subject. For each participant (e.g., \texttt{Subject01}), create subfolders \texttt{RGB\_Video/}, \texttt{Thermal\_Video/}, and \texttt{GSR\_Data/}.
    \item \textbf{File Naming:} Use a consistent scheme such as \texttt{SubjectID\_Task\_Modality.ext}. For example, \texttt{S01\_Baseline\_RGB.mp4}, \texttt{S01\_Math\_Thermal.mp4}, \texttt{S01\_Math\_ShimmerGSR.csv}, and \texttt{S01\_Math\_PhysioKitGSR.csv}.
    \item \textbf{Metadata Files:} Place the session log (e.g., \texttt{S01\_session.csv}) in the subject's main folder. Include columns: Task, StartTimestamp, EndTimestamp, SensorStatus, Notes.
    \item \textbf{Backup and Versioning:} Regularly back up data to a secure storage. Use version control (e.g., Git) for any processing scripts or annotation files.
\end{itemize}

\section{Anticipated Challenges and Mitigation Strategies}

We anticipate several potential challenges and plan to address them:

\begin{itemize}
    \item \textbf{Subject Movement:} Even small head or hand movements can disturb video tracking. We instruct participants to minimise motion and consider using a chinrest. In analysis, we will detect and possibly exclude frames with excessive motion blur.
    \item \textbf{Sensor Dropouts:} Wireless GSR sensors may temporarily lose connection. Using two independent GSR systems provides a backup. We will also monitor signals in real time and recalibrate or reattach sensors if noise is detected.
    \item \textbf{Lighting Variability:} Fluctuations in ambient light can affect RGB data. We control the room lighting and avoid sunlight. Tests are conducted to ensure no flicker from artificial lights at the camera frame rate.
    \item \textbf{Emotional Responsivity:} Individuals vary in emotional reactivity, so not all participants may show strong GSR changes to the same stimuli. We will collect subjective stress/arousal ratings (optional) to interpret the data. Our sample size planning accounts for variability.
    \item \textbf{Data Volume and Management:} Multimodal recordings generate large files. We will follow the naming and folder conventions strictly and perform real-time data backups after each session to prevent loss.
\end{itemize}

\section{Conclusion}

This comprehensive data collection guide provides both the practical procedures and theoretical justification for the GSR-RGBT project's experimental design. By following these protocols, researchers can collect high-quality, synchronized multimodal data suitable for training robust contactless GSR prediction models while ensuring fairness, reliability, and scientific rigor.

\end{document}